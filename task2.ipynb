{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitbasecondac64d282fa60a498fa283947468542966",
   "display_name": "Python 3.6.9 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2cc0a28750a97f3af66d5f5dbea248319d1ba299a184f0311f0cc2afdf3bf264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "The Pacman environment\n",
    "----------------------\n",
    "The Pacman is an agent that moves around the grid. When it encounters a cell with a breadcrumb, it \"eats\" it and gets a\n",
    "positive reward. When all of the breadcrumbs are consumed, he wins.\n",
    "\n",
    "The Pacman moves 1 cell for each timestep in one of 4 directions; up, down, left, right. All 4 sides of the \n",
    "environment grid contain obstacles so that the agent cannot move out of the grid. In addition there are more obstacles\n",
    "inside the grid as well. If the Pacman tries to move into an obstacle, he gets a negative reward and returns back to the \n",
    "cell he moved from. If the Pacman moves into an empty cell, he gets a small negative reward. This is an incentive to get \n",
    "games completed as quickly as possible.\n",
    "\n",
    "The whole algorithm is run from the code below.\n",
    "\n",
    "Before running this code, check in the config.py file for the configurable parameters used in this algorithm.\n",
    "This includes the number of breadcrumbs, the location of the breadcrumbs and the location of the obstacles.\n",
    "The Pacman is more likely to win if there are fewer breadcrumbs in the grid.\n",
    "\n",
    "The Pacman learns from completing a large number of episodes. If you intend to run lots of episodes, it is a \n",
    "good idea to set the flag show_step = False as step by step changes will output too many lines.\n",
    "\n",
    "The ghost provides stochasticity in the environment. \n",
    "\n",
    "If the Pacman moves onto the ghost, he loses. There is a flag \"Hyper.is_ghost\" which when set to True ensures\n",
    "there is a ghost in the environment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\n\n\n\n\n\n\n\n\n----------------------------------------------------------------------------------------------------\nStart of environment design for Pacman\nThe Hyperparameters\n-------------------\nThreshold for exploitation (epsilon) = 0.95\nepsilon decay = 0.995\nminimum value of epsilon = 0.001\nlearning rate (alpha) = 0.8\ndiscount factor (gamma) = 0.51\ntotal number of breadcrumbs 10\n----------------------------------------------------------------------------------------------------\nThe grid is updated and printed for each step. In each cell you see the following symbols:\nX - obstacle\n. - empty\nb - breadcrumb\nA - Agent (Pacman)\nG - Ghost\nCompleted environment after 1 episodes and 99 timesteps, total reward: -4543 with epsilon: 0.5783737835841118\nYou lost to the ghost!\nCompleted environment after 2 episodes and 43 timesteps, total reward: -1462 with epsilon: 0.4662309189661894\nYou lost to the ghost!\nCompleted environment after 3 episodes and 38 timesteps, total reward: -2088 with epsilon: 0.38537020987644216\nYou lost to the ghost!\nCompleted environment after 4 episodes and 22 timesteps, total reward: -1049 with epsilon: 0.34513254658172593\nYou lost to the ghost!\nCompleted environment after 5 episodes and 7 timesteps, total reward: -583 with epsilon: 0.3332325996105925\nYou lost to the ghost!\nCompleted environment after 6 episodes and 19 timesteps, total reward: -151 with epsilon: 0.30296050449939443\nYou lost to the ghost!\nCompleted environment after 7 episodes and 27 timesteps, total reward: -1252 with epsilon: 0.26461179293176074\nYou lost to the ghost!\nCompleted environment after 8 episodes and 15 timesteps, total reward: -147 with epsilon: 0.24544568790688226\nYou lost to the ghost!\nCompleted environment after 9 episodes and 6 timesteps, total reward: -182 with epsilon: 0.23817374808487615\nYou lost to the ghost!\nCompleted environment after 10 episodes and 70 timesteps, total reward: -1669 with epsilon: 0.16769091842207257\n"
     ]
    }
   ],
   "source": [
    "from grid import Pacman_grid\n",
    "from config import Hyper, Constants\n",
    "\n",
    "print(\"\\n\"*10)\n",
    "print(\"-\"*100)\n",
    "print(\"Start of environment design for Pacman\")\n",
    "Hyper.display()\n",
    "print(\"-\"*100)\n",
    "print(\"The grid is updated and printed for each step. In each cell you see the following symbols:\")\n",
    "print(\"X - obstacle\")\n",
    "print(\". - empty\")\n",
    "print(\"b - breadcrumb\")\n",
    "print(\"A - Agent (Pacman)\")\n",
    "print(\"G - Ghost\")\n",
    "pacman_grid = Pacman_grid()\n",
    "for i in range(Hyper.total_episodes):\n",
    "    pacman_grid.reset()\n",
    "    done = False\n",
    "    while done == False:\n",
    "        if Hyper.is_ghost:\n",
    "            done = pacman_grid.ghost_step(i)\n",
    "        else:\n",
    "            done = pacman_grid.step(i)\n",
    "        pacman_grid.policy.update_epsilon()\n",
    "    episodes = i + 1\n",
    "    pacman_grid.print_episode_results(episodes)\n",
    "    pacman_grid.save_episode_stats()\n",
    "\n",
    "pacman_grid.print_results()\n",
    "print(\"\\nThe grid is updated and printed for each step. In each cell you see the following symbols:\")\n",
    "print(\"X - obstacle\")\n",
    "print(\". - empty\")\n",
    "print(\"b - breadcrumb\")\n",
    "print(\"A - Agent (Pacman)\")\n",
    "print(\"G - Ghost\")\n",
    "print(\"\\n\"*3)  \n",
    "print(\"-\"*100)\n",
    "Hyper.display()\n",
    "print(\"End of environment design for Pacman\")\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "source": [
    "When all of the episodes are completed, look in the local images folder to view the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The next cell is code to run for Hyperameter tuning using the Optuna library.\n",
    "Please run the following command to install the Optuna library;\n",
    "\n",
    "pip install optuna\n",
    "\n",
    "Given the stochastic environment, I had to run 10,000 trials 4 times to get a good idea \n",
    "of what the best hyperparameters are. This takes a long time, about 3 hours.\n",
    "To check that the code works, you can run fewer trials, for example 1,000.\n",
    "The class libraries are the same as referenced in the previous cell."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-04-01 16:02:46,364]\u001b[0m A new study created in memory with name: no-name-889ab2ec-6de8-4ebe-87e6-29efbbae89c5\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:47,374]\u001b[0m Trial 0 finished with value: -175.09 and parameters: {'Hyper.gamma': 0.15616262555963364, 'Hyper.alpha': 0.9158543426419831, 'Hyper.init_epsilon': 0.9785465260795877, 'Hyper.epsilon_threshold': 0.06966007345727257, 'Hyper.decay': 0.9976583905436357}. Best is trial 0 with value: -175.09.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:48,790]\u001b[0m Trial 1 finished with value: -129.43 and parameters: {'Hyper.gamma': 0.7847656753730818, 'Hyper.alpha': 0.6003570414881729, 'Hyper.init_epsilon': 0.9872448490468405, 'Hyper.epsilon_threshold': 0.04849028134092385, 'Hyper.decay': 0.9909177477413627}. Best is trial 1 with value: -129.43.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:49,820]\u001b[0m Trial 2 finished with value: -32.33 and parameters: {'Hyper.gamma': 0.11191724226355902, 'Hyper.alpha': 0.7997231793718556, 'Hyper.init_epsilon': 0.9744286807986741, 'Hyper.epsilon_threshold': 0.002159873458454041, 'Hyper.decay': 0.9925150592942745}. Best is trial 2 with value: -32.33.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:50,917]\u001b[0m Trial 3 finished with value: -210.25 and parameters: {'Hyper.gamma': 0.7611674913696401, 'Hyper.alpha': 0.051059134234164305, 'Hyper.init_epsilon': 0.9724763703595118, 'Hyper.epsilon_threshold': 0.09500847066186512, 'Hyper.decay': 0.997550462657576}. Best is trial 2 with value: -32.33.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:51,956]\u001b[0m Trial 4 finished with value: -83.46 and parameters: {'Hyper.gamma': 0.4341306434090426, 'Hyper.alpha': 0.6694463381092144, 'Hyper.init_epsilon': 0.981137304888905, 'Hyper.epsilon_threshold': 0.032663318058907355, 'Hyper.decay': 0.9932000101307172}. Best is trial 2 with value: -32.33.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:53,319]\u001b[0m Trial 5 finished with value: -157.59 and parameters: {'Hyper.gamma': 0.865168071561949, 'Hyper.alpha': 0.8407138103132196, 'Hyper.init_epsilon': 0.9538378960989787, 'Hyper.epsilon_threshold': 0.06514550287923787, 'Hyper.decay': 0.9932476899676858}. Best is trial 2 with value: -32.33.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:54,396]\u001b[0m Trial 6 finished with value: -23.34 and parameters: {'Hyper.gamma': 0.45468772969721966, 'Hyper.alpha': 0.8135587982176923, 'Hyper.init_epsilon': 0.9025260450890925, 'Hyper.epsilon_threshold': 0.03994081411084624, 'Hyper.decay': 0.9934198563867496}. Best is trial 6 with value: -23.34.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:55,407]\u001b[0m Trial 7 finished with value: -252.77 and parameters: {'Hyper.gamma': 0.03605141913981986, 'Hyper.alpha': 0.9723011154757413, 'Hyper.init_epsilon': 0.9987077313904094, 'Hyper.epsilon_threshold': 0.08771154645599591, 'Hyper.decay': 0.9980021878161204}. Best is trial 6 with value: -23.34.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:56,520]\u001b[0m Trial 8 finished with value: -159.08 and parameters: {'Hyper.gamma': 0.16076546965588645, 'Hyper.alpha': 0.02397502059008991, 'Hyper.init_epsilon': 0.9013222929926838, 'Hyper.epsilon_threshold': 0.026210394037511957, 'Hyper.decay': 0.995819377997141}. Best is trial 6 with value: -23.34.\u001b[0m\n",
      "\u001b[32m[I 2021-04-01 16:02:57,599]\u001b[0m Trial 9 finished with value: -204.83 and parameters: {'Hyper.gamma': 0.07825956841933406, 'Hyper.alpha': 0.4371093545920138, 'Hyper.init_epsilon': 0.9069718823697956, 'Hyper.epsilon_threshold': 0.06023458260567268, 'Hyper.decay': 0.9982429674486145}. Best is trial 6 with value: -23.34.\u001b[0m\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of finished trials:  10\n",
      "The optimal hyperpameters are as follows;\n",
      "{'Hyper.gamma': 0.45468772969721966, 'Hyper.alpha': 0.8135587982176923, 'Hyper.init_epsilon': 0.9025260450890925, 'Hyper.epsilon_threshold': 0.03994081411084624, 'Hyper.decay': 0.9934198563867496}\n",
      "-23.34\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from grid import Pacman_grid\n",
    "from config import Hyper, Constants\n",
    "\n",
    "# This code uses the Optuna library to tune the hyperparameters\n",
    "# Instead of producing graphs, it produces statistics\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    Hyper.print_episodes = False    # Recommended do not show episode information, too much output\n",
    "    Hyper.gamma = trial.suggest_float(\"Hyper.gamma\", 0.01, 0.99)\n",
    "    Hyper.alpha = trial.suggest_float(\"Hyper.alpha\", 0.01, 0.99)\n",
    "    Hyper.init_epsilon = trial.suggest_float(\"Hyper.init_epsilon\", 0.9, 1)\n",
    "    Hyper.epsilon_threshold = trial.suggest_float(\"Hyper.epsilon_threshold\", 0.001, 0.1)\n",
    "    Hyper.decay = trial.suggest_float(\"Hyper.decay\", 0.990, 0.999)\n",
    "    pacman_grid = Pacman_grid()\n",
    "    for i in range(Hyper.total_episodes):\n",
    "        pacman_grid.reset()\n",
    "        done = False\n",
    "        while done == False:\n",
    "            if Hyper.is_ghost:\n",
    "                done = pacman_grid.ghost_step(i)\n",
    "            else:\n",
    "                done = pacman_grid.step(i)\n",
    "            pacman_grid.policy.update_epsilon()\n",
    "        episodes = i + 1\n",
    "        if Hyper.print_episodes:\n",
    "            pacman_grid.print_episode_results(episodes)\n",
    "        pacman_grid.save_episode_stats()\n",
    "\n",
    "    # Average the rewards at the end to even out any outlier results caused\n",
    "    # by the stochastic environment.\n",
    "    sample = 100\n",
    "    last_sample = -1 * sample\n",
    "    reward_for_last_sample_episode = sum(pacman_grid.rewards_per_episode[last_sample:]) / sample\n",
    "    return reward_for_last_sample_episode\n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "# Note n_trials=10000. This is a lot of trials and will take a long time to run, but the results will be better.\n",
    "# The important results are at the end of the printout\n",
    "study.optimize(objective, n_trials=10000)\n",
    "print(\"\\n\")\n",
    "print(\"-\"*100)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"The optimal hyperpameters are as follows;\")\n",
    "print(study.best_params)\n",
    "print(study.best_value)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}